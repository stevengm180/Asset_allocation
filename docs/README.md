# Structure Modulaire - PrÃ©diction des Allocations d'Actifs

## ğŸ“‚ Architecture

La structure a Ã©tÃ© dÃ©coupÃ©e en **modules Python indÃ©pendants et rÃ©utilisables** pour faciliter la maintenance, le testing et les extensions futures.

```
allocation_actifs/
â”œâ”€â”€ config.py                     # Configuration centralisÃ©e
â”œâ”€â”€ utils.py                      # Fonctions utilitaires (metrics, plots, reports)
â”œâ”€â”€ data_loading.py               # Chargement et exploration des donnÃ©es
â”œâ”€â”€ data_preparation.py           # Nettoyage, fusion, prÃ©paration
â”œâ”€â”€ feature_engineering.py        # CrÃ©ation des features
â”œâ”€â”€ exploratory_analysis.py       # Analyse exploratoire
â”œâ”€â”€ model_training.py             # EntraÃ®nement des modÃ¨les
â”œâ”€â”€ cross_validation.py           # Cross-validation et importance
â”œâ”€â”€ predictions.py                # GÃ©nÃ©ration des prÃ©dictions
â”œâ”€â”€ main_pipeline.ipynb           # Notebook orchestrateur (Ã  exÃ©cuter)
â”œâ”€â”€ research_structure.ipynb      # Ancien notebook (rÃ©fÃ©rence)
â””â”€â”€ README.md                     # Ce fichier
```

## ğŸ”§ Description des Modules

### 1. **config.py**
Configuration centralisÃ©e de tous les hyperparamÃ¨tres et chemins de fichiers.
- Colonnes de base (RET, SIGNED_VOLUME, etc.)
- Horizons de features
- ParamÃ¨tres LightGBM, Ridge, Random Forest
- Chemins des fichiers

**UtilitÃ©**: Modifier rapidement les hyperparamÃ¨tres sans toucher au code.

### 2. **utils.py**
Fonctions utilitaires rÃ©utilisables.
- `calculate_metrics()` - Calcul des mÃ©triques
- `plot_model_comparison()` - Visualisation comparative
- `plot_feature_importance()` - Graphique importance
- `plot_cv_scores()` - Evolution CV
- `print_summary_report()` - RÃ©sumÃ© exÃ©cutif

### 3. **data_loading.py**
Gestion du chargement et exploration des donnÃ©es.
- `load_data()` - Charge CSV
- `explore_data()` - Statistiques descriptives
- `get_data_summary()` - RÃ©sumÃ© clÃ©

### 4. **data_preparation.py**
Nettoyage et prÃ©paration des donnÃ©es.
- `prepare_data()` - Fusion X_train + y_train
- `handle_outliers_detection()` - DÃ©tection outliers
- `split_temporal_data()` - Split respectueux temporalitÃ©
- `prepare_features_for_modeling()` - PrÃ©pare X, y pour modÃ¨les

### 5. **feature_engineering.py**
IngÃ©nierie des features (+50 features crÃ©Ã©es).
- Moyennes mobiles (3, 5, 10, 15, 20j)
- VolatilitÃ© (std, skew, kurtosis)
- Features de momentum
- Features de volume
- Interactions
- AgrÃ©gations par groupe

### 6. **exploratory_analysis.py**
Analyse exploratoire des features.
- `analyze_correlations()` - CorrÃ©lation avec cible
- `analyze_features_by_class()` - Comparaison positif/nÃ©gatif
- `get_feature_statistics()` - Stats complÃ¨tes

### 7. **model_training.py**
EntraÃ®nement des modÃ¨les.
- `train_ridge()` - Ridge Regression
- `train_logistic()` - Logistic Regression
- `train_random_forest()` - Random Forest
- `train_lightgbm()` - LightGBM
- `train_base_models()` - Lance tous les modÃ¨les
- `create_results_dataframe()` - RÃ©sumÃ© rÃ©sultats

### 8. **cross_validation.py**
Cross-validation et analyse de performance.
- `perform_time_series_cross_validation()` - CV respectueuse temporalitÃ©
- `plot_cv_results()` - Visualisation CV
- `get_feature_importance()` - Importance moyenne des folds
- `analyze_cv_performance()` - Stats CV

### 9. **predictions.py**
GÃ©nÃ©ration des prÃ©dictions finales.
- `train_final_model()` - ModÃ¨le final sur all data
- `generate_predictions()` - PrÃ©dictions sur test set
- `save_submissions()` - Sauvegarde CSV
- `compare_predictions()` - Compare les modÃ¨les

### 10. **main_pipeline.ipynb** â­
**NOTEBOOK Ã€ EXÃ‰CUTER** - Orchestre tous les modules.

```
Ã‰TAPE 1: Chargement et Exploration
Ã‰TAPE 2: PrÃ©paration des DonnÃ©es
Ã‰TAPE 3: IngÃ©nierie des Features
Ã‰TAPE 4: Analyse Exploratoire
Ã‰TAPE 5: PrÃ©paration pour ModÃ©lisation
Ã‰TAPE 6: EntraÃ®nement ModÃ¨les de Base
Ã‰TAPE 7: Cross-Validation
Ã‰TAPE 8: PrÃ©dictions Finales
Ã‰TAPE 9: RÃ©sumÃ© ExÃ©cutif
```

## ğŸš€ Utilisation

### Option 1: ExÃ©cuter le Pipeline Complet

```bash
# Ouvrir main_pipeline.ipynb dans Jupyter
jupyter notebook main_pipeline.ipynb

# Puis exÃ©cuter les cellules dans l'ordre
```

### Option 2: Utiliser les Modules Individuellement

```python
# Exemple: accÃ©der uniquement au data loading
from data_loading import load_data, explore_data
X_train, y_train, X_test, sample_submission = load_data()
explore_data(X_train, y_train, X_test)

# Exemple: crÃ©er les features
from feature_engineering import create_all_features
train_data, X_test, all_features = create_all_features(train_data, X_test)

# Exemple: entraÃ®ner LightGBM seulement
from model_training import train_lightgbm
model, train_acc, val_acc = train_lightgbm(X_train, y_train, X_val, y_val)
```

### Option 3: Personnaliser la Configuration

```python
# config.py
# Modifier les hyperparamÃ¨tres:
LGBM_PARAMS = {
    "learning_rate": 0.1,  # Plus rapide
    "max_depth": 7,         # Plus profond
    ...
}
```

## ğŸ“Š Fichiers de Sortie

Les fichiers de soumission gÃ©nÃ©rÃ©s:
- `submission_lgbm_final.csv` - ModÃ¨le LightGBM entraÃ®nÃ© sur toutes les donnÃ©es
- `submission_ensemble.csv` - Moyenne des prÃ©dictions des 8 folds CV (â­ **RecommandÃ©**)
- `submission_ridge_baseline.csv` - Baseline Ridge

## ğŸ”„ Workflow de DÃ©veloppement

### Pour tester une nouvelle idÃ©e:

1. **Feature Engineering**: Ajouter dans `feature_engineering.py`
```python
# Dans create_all_features()
train_data['NEW_FEATURE'] = ...
X_test['NEW_FEATURE'] = ...
```

2. **Modifier config**: Ajouter le nouveau paramÃ¨tre si nÃ©cessaire
```python
# config.py
LGBM_PARAMS['new_param'] = value
```

3. **Tester dans main_pipeline.ipynb**: Les modules chargeront automatiquement

### Pour tester un nouveau modÃ¨le:

1. **CrÃ©er la fonction** dans `model_training.py`
```python
def train_my_model(X_train, y_train, X_val, y_val):
    model = MyModel()
    model.fit(X_train, y_train)
    return model, train_acc, val_acc
```

2. **Ajouter Ã  `train_base_models()`**
```python
my_model, mt_train, mt_val = train_my_model(...)
results['MyModel'] = {...}
```

3. **ExÃ©cuter main_pipeline.ipynb**

## âœ¨ Avantages de cette Structure

âœ… **Modulaire**: Chaque fonction a une responsabilitÃ© unique  
âœ… **RÃ©utilisable**: Les modules peuvent Ãªtre importÃ©s n'importe oÃ¹  
âœ… **Testable**: Facile d'Ã©crire des tests unitaires  
âœ… **Maintenable**: Code lisible et organisÃ©  
âœ… **Ã‰volutif**: Facile d'ajouter de nouvelles features/modÃ¨les  
âœ… **Configurable**: Tous les paramÃ¨tres en un seul fichier  

## ğŸ“ Notes

- Tous les modules utilisent des chemins **relatifs**
- Les fichiers CSV sont chargÃ©s du rÃ©pertoire courant
- La structure respecte la **temporalitÃ©** des donnÃ©es (important!)
- La mÃ©trique utilisÃ©e est l'**Accuracy** (prÃ©diction du signe)

## ğŸ”— Prochaines Ã‰tapes

- ImplÃ©menter l'optimisation des hyperparamÃ¨tres (Optuna)
- Ajouter des techniques d'ensemble (stacking, blending)
- ImplÃ©menter une feature selection automatique
- Ajouter des tests unitaires
- CrÃ©er une API Flask pour les prÃ©dictions

---

**Version**: 1.0  
**Date**: Janvier 2026  
**Statut**: Production-Ready âœ…
