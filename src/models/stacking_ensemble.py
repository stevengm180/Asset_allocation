"""
Module de stacking ensemble - Meta-learning
Combine les prÃ©dictions des modÃ¨les avec un meta-modÃ¨le
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import Ridge, LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import lightgbm as lgbm


def create_stacking_features(cv_models, lgbm_final, X_train, X_val, X_test):
    """
    CrÃ©e des features de stacking Ã  partir des prÃ©dictions.
    
    Parameters
    ----------
    cv_models : list
        ModÃ¨les LightGBM des folds CV
    lgbm_final : lgbm.Booster
        ModÃ¨le LightGBM entraÃ®nÃ© sur toutes les donnÃ©es
    X_train, X_val, X_test : pd.DataFrame
        
    Returns
    -------
    tuple
        (X_train_meta, X_val_meta, X_test_meta)
    """
    print("ðŸ”— CrÃ©ation des features de stacking...\n")
    
    n_folds = len(cv_models)
    
    # Train features
    X_train_meta = np.zeros((X_train.shape[0], n_folds + 1))
    for i, model in enumerate(cv_models):
        X_train_meta[:, i] = model.predict(X_train)
    X_train_meta[:, -1] = lgbm_final.predict(X_train)
    
    # Val features
    X_val_meta = np.zeros((X_val.shape[0], n_folds + 1))
    for i, model in enumerate(cv_models):
        X_val_meta[:, i] = model.predict(X_val)
    X_val_meta[:, -1] = lgbm_final.predict(X_val)
    
    # Test features
    X_test_meta = np.zeros((X_test.shape[0], n_folds + 1))
    for i, model in enumerate(cv_models):
        X_test_meta[:, i] = model.predict(X_test)
    X_test_meta[:, -1] = lgbm_final.predict(X_test)
    
    print(f"âœ“ Features de stacking crÃ©Ã©es: shape {X_train_meta.shape}")
    print(f"  {n_folds} folds CV + modÃ¨le final = {n_folds + 1} meta-features")
    
    return X_train_meta, X_val_meta, X_test_meta


def train_stacking_meta_model(X_train_meta, y_train, X_val_meta, y_val):
    """
    EntraÃ®ne le meta-modÃ¨le Ridge sur les features de stacking.
    
    Parameters
    ----------
    X_train_meta : np.ndarray
        Features de stacking train
    y_train : pd.Series
    X_val_meta : np.ndarray
        Features de stacking val
    y_val : pd.Series
        
    Returns
    -------
    Ridge, float
        Meta-modÃ¨le et accuracy
    """
    print("\nðŸŽ¯ EntraÃ®nement du meta-modÃ¨le (Ridge)...\n")
    
    meta_model = Ridge(alpha=0.1)
    meta_model.fit(X_train_meta, y_train)
    
    # Ã‰valuation
    y_train_pred = (meta_model.predict(X_train_meta) > 0.5).astype(int)
    y_val_pred = (meta_model.predict(X_val_meta) > 0.5).astype(int)
    
    train_acc = accuracy_score(y_train, y_train_pred)
    val_acc = accuracy_score(y_val, y_val_pred)
    
    print(f"  Train Accuracy: {train_acc:.4f}")
    print(f"  Val Accuracy: {val_acc:.4f}")
    
    return meta_model, val_acc


def generate_stacking_predictions(meta_model, X_test_meta):
    """
    GÃ©nÃ¨re les prÃ©dictions avec le meta-modÃ¨le.
    
    Parameters
    ----------
    meta_model : Ridge
    X_test_meta : np.ndarray
        
    Returns
    -------
    np.ndarray
        PrÃ©dictions binaires
    """
    print("\nðŸ“Š GÃ©nÃ©ration des prÃ©dictions avec stacking...\n")
    
    predictions_proba = meta_model.predict(X_test_meta)
    predictions = (predictions_proba > 0.5).astype(int)
    
    print(f"âœ“ Positif: {predictions.sum():,} ({predictions.mean():.2%})")
    
    return predictions, predictions_proba


def compare_stacking_vs_ensemble(predictions_simple_ensemble, predictions_stacking):
    """
    Compare les prÃ©dictions simples et stacking.
    """
    print("\nðŸ“ˆ Comparaison Ensemble Simple vs Stacking:\n")
    
    agreement = (predictions_simple_ensemble == predictions_stacking).mean()
    print(f"  Accord entre les deux: {agreement:.2%}")
    
    diff = np.abs(predictions_simple_ensemble.sum() - predictions_stacking.sum())
    print(f"  DiffÃ©rence de positifs: {diff} samples")
    
    return agreement


def multi_level_stacking(cv_models, lgbm_final, X_train, X_val, X_test, y_train, y_val):
    """
    CrÃ©e un stacking multi-niveau pour plus de stabilitÃ©.
    
    Parameters
    ----------
    cv_models : list
    lgbm_final : lgbm.Booster
    X_train, X_val, X_test : pd.DataFrame
    y_train, y_val : pd.Series
        
    Returns
    -------
    tuple
        (predictions, meta_model_accuracy)
    """
    print("ðŸ”ï¸ MULTI-LEVEL STACKING\n")
    
    # Level 1: PrÃ©dictions des modÃ¨les
    X_train_meta, X_val_meta, X_test_meta = create_stacking_features(
        cv_models, lgbm_final, X_train, X_val, X_test
    )
    
    # Level 2: Meta-modÃ¨le
    meta_model, meta_acc = train_stacking_meta_model(X_train_meta, y_train, X_val_meta, y_val)
    
    # PrÃ©dictions finales
    predictions, predictions_proba = generate_stacking_predictions(meta_model, X_test_meta)
    
    return predictions, meta_acc, meta_model


def weighted_ensemble(cv_models, lgbm_final, X_test, cv_scores):
    """
    CrÃ©e un ensemble pondÃ©rÃ© basÃ© sur les performances CV.
    
    Parameters
    ----------
    cv_models : list
    lgbm_final : lgbm.Booster
    X_test : pd.DataFrame
    cv_scores : list
        Scores de chaque fold
        
    Returns
    -------
    np.ndarray
        PrÃ©dictions pondÃ©rÃ©es
    """
    print("âš–ï¸ WEIGHTED ENSEMBLE (basÃ© sur CV scores)\n")
    
    # Normaliser les poids
    weights = np.array(cv_scores)
    weights = weights / weights.sum()
    
    print(f"  Poids CV: {[f'{w:.3f}' for w in weights]}\n")
    
    # PrÃ©dictions pondÃ©rÃ©es
    ensemble_pred = np.zeros(X_test.shape[0])
    
    for i, (model, weight) in enumerate(zip(cv_models, weights)):
        pred = model.predict(X_test)
        ensemble_pred += weight * pred
        print(f"  Fold {i+1}: poids={weight:.3f}")
    
    # Ajouter le modÃ¨le final (poids Ã©gal Ã  la moyenne des CV)
    final_weight = weights.mean()
    ensemble_pred += final_weight * lgbm_final.predict(X_test)
    print(f"  Final: poids={final_weight:.3f}")
    
    # Renormaliser
    n_models = len(cv_models) + 1
    ensemble_pred = ensemble_pred / n_models
    
    predictions = (ensemble_pred > 0.5).astype(int)
    
    print(f"\nâœ“ Positif: {predictions.sum():,} ({predictions.mean():.2%})")
    
    return predictions
