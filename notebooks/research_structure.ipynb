{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4acbfbc",
   "metadata": {},
   "source": [
    "# PrÃ©diction des Allocations d'Actifs - Structure de Recherche ComplÃ¨te\n",
    "\n",
    "Ce notebook implÃ©mente une structure de recherche complÃ¨te pour prÃ©dire le signe des rendements futurs des allocations d'actifs.\n",
    "\n",
    "**MÃ©trique**: Accuracy (capacitÃ© Ã  prÃ©dire correctement le signe du rendement futur)\n",
    "\n",
    "**Objectif**: Pour chaque allocation, prÃ©dire si elle devrait Ãªtre suivie (positive) ou shorÃ©e (nÃ©gative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88dd4f3",
   "metadata": {},
   "source": [
    "## 1. Chargement et Exploration des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06df6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgbm\n",
    "from optuna import create_study, trial\n",
    "import optuna\n",
    "\n",
    "# Config\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ“ Toutes les librairies importÃ©es avec succÃ¨s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donnÃ©es\n",
    "print(\"Chargement des donnÃ©es...\")\n",
    "X_train = pd.read_csv('X_train_9xQjqvZ.csv', index_col='ROW_ID')\n",
    "y_train = pd.read_csv('y_train_Ppwhaz8.csv', index_col='ROW_ID')\n",
    "X_test = pd.read_csv('X_test_1zTtEnD.csv', index_col='ROW_ID')\n",
    "sample_submission = pd.read_csv('sample_submission_SpGVFuH.csv', index_col='ROW_ID')\n",
    "\n",
    "print(f\"\\nðŸ“Š Dimensions des donnÃ©es:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"sample_submission: {sample_submission.shape}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Colonnes de X_train:\")\n",
    "print(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f6a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration des donnÃ©es\n",
    "print(\"\\nðŸ” Info sur X_train:\")\n",
    "print(f\"Types de donnÃ©es:\\n{X_train.dtypes.value_counts()}\")\n",
    "print(f\"\\nValeurs manquantes:\\n{X_train.isnull().sum().sum()} valeurs manquantes au total\")\n",
    "\n",
    "print(\"\\nðŸ“Š Statistiques descriptives (premiers 5 colonnes):\")\n",
    "print(X_train.iloc[:, :5].describe().T)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Distribution de la cible y_train:\")\n",
    "print(y_train['target'].describe())\n",
    "print(f\"\\nSigne de la cible:\")\n",
    "print(f\"Positif (>0): {(y_train['target'] > 0).sum()} ({(y_train['target'] > 0).sum() / len(y_train) * 100:.1f}%)\")\n",
    "print(f\"NÃ©gatif (<=0): {(y_train['target'] <= 0).sum()} ({(y_train['target'] <= 0).sum() / len(y_train) * 100:.1f}%)\")\n",
    "\n",
    "# Visualisation de la distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axes[0].hist(y_train['target'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Rendement futur')\n",
    "axes[0].set_ylabel('FrÃ©quence')\n",
    "axes[0].set_title('Distribution des rendements futurs')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "axes[1].bar(['Positif', 'NÃ©gatif'], [(y_train['target'] > 0).sum(), (y_train['target'] <= 0).sum()])\n",
    "axes[1].set_ylabel('Nombre d\\'observations')\n",
    "axes[1].set_title('Balance des classes')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055e828",
   "metadata": {},
   "source": [
    "## 2. PrÃ©paration et Nettoyage des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des donnÃ©es\n",
    "train_data = X_train.copy()\n",
    "train_data['target'] = y_train['target'].values\n",
    "\n",
    "print(f\"âœ“ Fusion complÃ¨te: {train_data.shape}\")\n",
    "\n",
    "# Traitement des valeurs manquantes\n",
    "print(f\"\\nValeurs manquantes par colonne (non-zÃ©ro):\")\n",
    "missing = train_data.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "# Remplir les valeurs manquantes avec 0 (stratÃ©gie acceptable pour ce type de donnÃ©es)\n",
    "train_data = train_data.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "print(\"âœ“ Valeurs manquantes remplies\")\n",
    "\n",
    "# DÃ©tecter et gÃ©rer les outliers\n",
    "print(f\"\\nDÃ©tection des outliers (Â± 3 Ã©carts-types):\")\n",
    "base_features = [col for col in train_data.columns if col.startswith('RET_') or col.startswith('SIGNED_VOLUME_')]\n",
    "outliers_count = 0\n",
    "for col in base_features[:5]:  # VÃ©rifier les 5 premiers\n",
    "    Q1 = train_data[col].quantile(0.25)\n",
    "    Q3 = train_data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((train_data[col] < Q1 - 3*IQR) | (train_data[col] > Q3 + 3*IQR)).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"{col}: {outliers} outliers\")\n",
    "\n",
    "print(\"\\nâœ“ DonnÃ©es prÃ©parÃ©es et nettoyÃ©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a5f542",
   "metadata": {},
   "source": [
    "## 3. IngÃ©nierie des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©finir les colonnes de base\n",
    "RET_features = [f'RET_{i}' for i in range(1, 21)]\n",
    "SIGNED_VOLUME_features = [f'SIGNED_VOLUME_{i}' for i in range(1, 21)]\n",
    "\n",
    "print(\"ðŸ“ˆ Construction des features additionnelles...\\n\")\n",
    "\n",
    "# === GROUPE 1: Moyennes des rendements Ã  diffÃ©rents horizons ===\n",
    "for horizon in [3, 5, 10, 15, 20]:\n",
    "    train_data[f'AVERAGE_PERF_{horizon}'] = train_data[RET_features[:horizon]].mean(1)\n",
    "    X_test[f'AVERAGE_PERF_{horizon}'] = X_test[RET_features[:horizon]].mean(1)\n",
    "print(\"âœ“ Moyennes des rendements (horizons: 3, 5, 10, 15, 20)\")\n",
    "\n",
    "# === GROUPE 2: Moyennes par allocation et par date ===\n",
    "for horizon in [3, 5, 10, 15, 20]:\n",
    "    train_data[f'ALLOCATIONS_AVERAGE_PERF_{horizon}'] = train_data.groupby('TS')[f'AVERAGE_PERF_{horizon}'].transform('mean')\n",
    "    X_test[f'ALLOCATIONS_AVERAGE_PERF_{horizon}'] = X_test.groupby('TS')[f'AVERAGE_PERF_{horizon}'].transform('mean')\n",
    "print(\"âœ“ Moyennes des rendements agrÃ©gÃ©es par date\")\n",
    "\n",
    "# === GROUPE 3: VolatilitÃ© ===\n",
    "train_data['STD_PERF_20'] = train_data[RET_features].std(1)\n",
    "train_data['ALLOCATIONS_STD_PERF_20'] = train_data.groupby('TS')['STD_PERF_20'].transform('mean')\n",
    "X_test['STD_PERF_20'] = X_test[RET_features].std(1)\n",
    "X_test['ALLOCATIONS_STD_PERF_20'] = X_test.groupby('TS')['STD_PERF_20'].transform('mean')\n",
    "print(\"âœ“ VolatilitÃ© des rendements\")\n",
    "\n",
    "# === GROUPE 4: Statistiques additionnelles des rendements ===\n",
    "train_data['SKEW_PERF_20'] = train_data[RET_features].skew(1)\n",
    "train_data['KURT_PERF_20'] = train_data[RET_features].kurtosis(1)\n",
    "train_data['MIN_PERF_20'] = train_data[RET_features].min(1)\n",
    "train_data['MAX_PERF_20'] = train_data[RET_features].max(1)\n",
    "train_data['RANGE_PERF_20'] = train_data['MAX_PERF_20'] - train_data['MIN_PERF_20']\n",
    "\n",
    "X_test['SKEW_PERF_20'] = X_test[RET_features].skew(1)\n",
    "X_test['KURT_PERF_20'] = X_test[RET_features].kurtosis(1)\n",
    "X_test['MIN_PERF_20'] = X_test[RET_features].min(1)\n",
    "X_test['MAX_PERF_20'] = X_test[RET_features].max(1)\n",
    "X_test['RANGE_PERF_20'] = X_test['MAX_PERF_20'] - X_test['MIN_PERF_20']\n",
    "print(\"âœ“ Skewness, Kurtosis, Min, Max, Range\")\n",
    "\n",
    "# === GROUPE 5: Features de momentum ===\n",
    "train_data['RECENT_PERF_5'] = train_data[RET_features[:5]].mean(1)\n",
    "train_data['EARLY_PERF_5'] = train_data[RET_features[-5:]].mean(1)\n",
    "train_data['MOMENTUM_RATIO'] = train_data['RECENT_PERF_5'] / (train_data['EARLY_PERF_5'] + 1e-8)\n",
    "\n",
    "X_test['RECENT_PERF_5'] = X_test[RET_features[:5]].mean(1)\n",
    "X_test['EARLY_PERF_5'] = X_test[RET_features[-5:]].mean(1)\n",
    "X_test['MOMENTUM_RATIO'] = X_test['RECENT_PERF_5'] / (X_test['EARLY_PERF_5'] + 1e-8)\n",
    "print(\"âœ“ Features de momentum\")\n",
    "\n",
    "# === GROUPE 6: Features de volume ===\n",
    "train_data['AVERAGE_VOLUME_20'] = train_data[SIGNED_VOLUME_features].mean(1)\n",
    "train_data['STD_VOLUME_20'] = train_data[SIGNED_VOLUME_features].std(1)\n",
    "train_data['RECENT_VOLUME_5'] = train_data[SIGNED_VOLUME_features[:5]].mean(1)\n",
    "\n",
    "X_test['AVERAGE_VOLUME_20'] = X_test[SIGNED_VOLUME_features].mean(1)\n",
    "X_test['STD_VOLUME_20'] = X_test[SIGNED_VOLUME_features].std(1)\n",
    "X_test['RECENT_VOLUME_5'] = X_test[SIGNED_VOLUME_features[:5]].mean(1)\n",
    "print(\"âœ“ Features de volume\")\n",
    "\n",
    "# === GROUPE 7: Interaction turnover-performance ===\n",
    "train_data['TURNOVER_PERF_INTERACTION'] = train_data['MEDIAN_DAILY_TURNOVER'] * train_data['AVERAGE_PERF_20']\n",
    "X_test['TURNOVER_PERF_INTERACTION'] = X_test['MEDIAN_DAILY_TURNOVER'] * X_test['AVERAGE_PERF_20']\n",
    "print(\"âœ“ Interactions turnover-performance\")\n",
    "\n",
    "# === GROUPE 8: Features agrÃ©gÃ©es par groupe ===\n",
    "train_data['GROUP_AVERAGE_PERF'] = train_data.groupby('GROUP')['AVERAGE_PERF_20'].transform('mean')\n",
    "train_data['GROUP_AVERAGE_TURNOVER'] = train_data.groupby('GROUP')['MEDIAN_DAILY_TURNOVER'].transform('mean')\n",
    "X_test['GROUP_AVERAGE_PERF'] = X_test.groupby('GROUP')['AVERAGE_PERF_20'].transform('mean')\n",
    "X_test['GROUP_AVERAGE_TURNOVER'] = X_test.groupby('GROUP')['MEDIAN_DAILY_TURNOVER'].transform('mean')\n",
    "print(\"âœ“ Features agrÃ©gÃ©es par groupe\")\n",
    "\n",
    "print(f\"\\nâœ“ Feature engineering complet!\")\n",
    "print(f\"X_train nouvelles dimensions: {train_data.shape}\")\n",
    "print(f\"X_test nouvelles dimensions: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister toutes les features disponibles\n",
    "all_features = RET_features + SIGNED_VOLUME_features + ['MEDIAN_DAILY_TURNOVER']\n",
    "all_features += [f'AVERAGE_PERF_{i}' for i in [3, 5, 10, 15, 20]]\n",
    "all_features += [f'ALLOCATIONS_AVERAGE_PERF_{i}' for i in [3, 5, 10, 15, 20]]\n",
    "all_features += ['STD_PERF_20', 'ALLOCATIONS_STD_PERF_20']\n",
    "all_features += ['SKEW_PERF_20', 'KURT_PERF_20', 'MIN_PERF_20', 'MAX_PERF_20', 'RANGE_PERF_20']\n",
    "all_features += ['RECENT_PERF_5', 'EARLY_PERF_5', 'MOMENTUM_RATIO']\n",
    "all_features += ['AVERAGE_VOLUME_20', 'STD_VOLUME_20', 'RECENT_VOLUME_5']\n",
    "all_features += ['TURNOVER_PERF_INTERACTION']\n",
    "all_features += ['GROUP_AVERAGE_PERF', 'GROUP_AVERAGE_TURNOVER']\n",
    "\n",
    "print(f\"ðŸ“Š Total features disponibles: {len(all_features)}\")\n",
    "print(f\"   - Base features: {len(RET_features + SIGNED_VOLUME_features + ['MEDIAN_DAILY_TURNOVER'])}\")\n",
    "print(f\"   - Features dÃ©rivÃ©es: {len(all_features) - len(RET_features + SIGNED_VOLUME_features + ['MEDIAN_DAILY_TURNOVER'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f07be8",
   "metadata": {},
   "source": [
    "## 4. Analyse Exploratoire des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28365849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des corrÃ©lations avec la cible\n",
    "print(\"ðŸ“Š Top 20 features les plus corrÃ©lÃ©es avec la cible:\\n\")\n",
    "correlations = train_data[all_features + ['target']].corr()['target'].drop('target').abs().sort_values(ascending=False)\n",
    "print(correlations.head(20))\n",
    "\n",
    "# Visualisation des corrÃ©lations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Top corrÃ©lations\n",
    "top_corr = train_data[correlations.head(15).index.tolist() + ['target']].corr()['target'].drop('target').sort_values()\n",
    "top_corr.plot(kind='barh', ax=axes[0], color=['red' if x < 0 else 'green' for x in top_corr])\n",
    "axes[0].set_xlabel('CorrÃ©lation avec la cible')\n",
    "axes[0].set_title('Top 15 features corrÃ©lÃ©es avec la cible')\n",
    "axes[0].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Distribution des corrÃ©lations\n",
    "axes[1].hist(correlations.values, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('CorrÃ©lation absolue')\n",
    "axes[1].set_ylabel('Nombre de features')\n",
    "axes[1].set_title('Distribution des corrÃ©lations avec la cible')\n",
    "axes[1].axvline(x=correlations.mean(), color='red', linestyle='--', label=f'Moyenne: {correlations.mean():.4f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCorrÃ©lation moyenne avec la cible: {correlations.mean():.4f}\")\n",
    "print(f\"Max corrÃ©lation: {correlations.max():.4f}\")\n",
    "print(f\"Min corrÃ©lation: {correlations.min():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6166084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des features par classe\n",
    "print(\"\\nðŸ“ˆ Analyse des features par classe (Positif vs NÃ©gatif):\\n\")\n",
    "\n",
    "positive_mask = train_data['target'] > 0\n",
    "negative_mask = train_data['target'] <= 0\n",
    "\n",
    "top_20_features = correlations.head(20).index.tolist()\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': top_20_features,\n",
    "    'Mean_Positive': [train_data.loc[positive_mask, feat].mean() for feat in top_20_features],\n",
    "    'Mean_Negative': [train_data.loc[negative_mask, feat].mean() for feat in top_20_features],\n",
    "})\n",
    "\n",
    "comparison_df['Difference'] = comparison_df['Mean_Positive'] - comparison_df['Mean_Negative']\n",
    "print(comparison_df.to_string())\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "comparison_df.sort_values('Difference', ascending=True).plot(\n",
    "    x='Feature', \n",
    "    y=['Mean_Positive', 'Mean_Negative'], \n",
    "    kind='barh',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel('Moyenne de la feature')\n",
    "ax.set_title('Moyennes des top features par classe')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f40d81",
   "metadata": {},
   "source": [
    "## 5. EntraÃ®nement des ModÃ¨les de Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrÃ©paration des donnÃ©es pour modÃ©lisation\n",
    "X = train_data[all_features].fillna(0)\n",
    "y = (train_data['target'] > 0).astype(int)\n",
    "\n",
    "print(f\"âœ“ DonnÃ©es prÃ©parÃ©es:\")\n",
    "print(f\"  X: {X.shape}\")\n",
    "print(f\"  y: {y.shape}\")\n",
    "print(f\"  Classes: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Split temporel (respecter l'ordre temporel)\n",
    "train_dates = train_data['TS'].unique()\n",
    "n_train_dates = int(len(train_dates) * 0.7)\n",
    "train_date_split = train_dates[n_train_dates]\n",
    "\n",
    "train_mask = train_data['TS'] < train_date_split\n",
    "test_mask = train_data['TS'] >= train_date_split\n",
    "\n",
    "X_train_split = X[train_mask]\n",
    "y_train_split = y[train_mask]\n",
    "X_val_split = X[test_mask]\n",
    "y_val_split = y[test_mask]\n",
    "\n",
    "print(f\"\\nðŸ“Š Split temporel:\")\n",
    "print(f\"  Train: {X_train_split.shape[0]} samples\")\n",
    "print(f\"  Val: {X_val_split.shape[0]} samples\")\n",
    "\n",
    "# Dictionnaire pour stocker les rÃ©sultats\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL 1: Ridge Regression ===\n",
    "print(\"ðŸ”µ EntraÃ®nement Ridge Regression...\")\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_split, y_train_split)\n",
    "\n",
    "ridge_train_acc = accuracy_score(y_train_split, (ridge.predict(X_train_split) > 0.5).astype(int))\n",
    "ridge_val_acc = accuracy_score(y_val_split, (ridge.predict(X_val_split) > 0.5).astype(int))\n",
    "\n",
    "results['Ridge'] = {\n",
    "    'model': ridge,\n",
    "    'train_acc': ridge_train_acc,\n",
    "    'val_acc': ridge_val_acc\n",
    "}\n",
    "\n",
    "print(f\"  Train Accuracy: {ridge_train_acc:.4f}\")\n",
    "print(f\"  Val Accuracy: {ridge_val_acc:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ecb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL 2: LightGBM (Gradient Boosting) ===\n",
    "print(\"ðŸŸ¢ EntraÃ®nement LightGBM...\")\n",
    "lgbm_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"num_threads\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"verbosity\": -1,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 5,\n",
    "    \"num_leaves\": 31,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "}\n",
    "\n",
    "train_data_lgbm = lgbm.Dataset(X_train_split, label=y_train_split)\n",
    "lgbm_model = lgbm.train(lgbm_params, train_data_lgbm, num_boost_round=300, valid_names=['train'])\n",
    "\n",
    "lgbm_train_pred = (lgbm_model.predict(X_train_split) > 0.5).astype(int)\n",
    "lgbm_val_pred = (lgbm_model.predict(X_val_split) > 0.5).astype(int)\n",
    "\n",
    "lgbm_train_acc = accuracy_score(y_train_split, lgbm_train_pred)\n",
    "lgbm_val_acc = accuracy_score(y_val_split, lgbm_val_pred)\n",
    "\n",
    "results['LightGBM'] = {\n",
    "    'model': lgbm_model,\n",
    "    'train_acc': lgbm_train_acc,\n",
    "    'val_acc': lgbm_val_acc\n",
    "}\n",
    "\n",
    "print(f\"  Train Accuracy: {lgbm_train_acc:.4f}\")\n",
    "print(f\"  Val Accuracy: {lgbm_val_acc:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ae9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL 3: Logistic Regression ===\n",
    "print(\"ðŸ”´ EntraÃ®nement Logistic Regression...\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_split)\n",
    "X_val_scaled = scaler.transform(X_val_split)\n",
    "\n",
    "logistic = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "logistic.fit(X_train_scaled, y_train_split)\n",
    "\n",
    "logistic_train_acc = accuracy_score(y_train_split, logistic.predict(X_train_scaled))\n",
    "logistic_val_acc = accuracy_score(y_val_split, logistic.predict(X_val_scaled))\n",
    "\n",
    "results['LogisticRegression'] = {\n",
    "    'model': logistic,\n",
    "    'train_acc': logistic_train_acc,\n",
    "    'val_acc': logistic_val_acc\n",
    "}\n",
    "\n",
    "print(f\"  Train Accuracy: {logistic_train_acc:.4f}\")\n",
    "print(f\"  Val Accuracy: {logistic_val_acc:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d861180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL 4: Random Forest ===\n",
    "print(\"ðŸŸ  EntraÃ®nement Random Forest...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_split, y_train_split)\n",
    "\n",
    "rf_train_acc = accuracy_score(y_train_split, rf.predict(X_train_split))\n",
    "rf_val_acc = accuracy_score(y_val_split, rf.predict(X_val_split))\n",
    "\n",
    "results['RandomForest'] = {\n",
    "    'model': rf,\n",
    "    'train_acc': rf_train_acc,\n",
    "    'val_acc': rf_val_acc\n",
    "}\n",
    "\n",
    "print(f\"  Train Accuracy: {rf_train_acc:.4f}\")\n",
    "print(f\"  Val Accuracy: {rf_val_acc:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©sumÃ© des rÃ©sultats\n",
    "print(\"ðŸ“Š RÃ‰SUMÃ‰ DES MODÃˆLES DE BASE:\\n\")\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Train Accuracy': [results[m]['train_acc'] for m in results.keys()],\n",
    "    'Val Accuracy': [results[m]['val_acc'] for m in results.keys()]\n",
    "})\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "best_model_name = summary_df.loc[summary_df['Val Accuracy'].idxmax(), 'Model']\n",
    "best_val_acc = summary_df['Val Accuracy'].max()\n",
    "print(f\"\\nâœ¨ Meilleur modÃ¨le: {best_model_name} (Accuracy: {best_val_acc:.4f})\")\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(summary_df))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, summary_df['Train Accuracy'], width, label='Train', alpha=0.8)\n",
    "ax.bar(x + width/2, summary_df['Val Accuracy'], width, label='Val', alpha=0.8)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Comparaison des modÃ¨les de base')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(summary_df['Model'])\n",
    "ax.legend()\n",
    "ax.set_ylim([0.5, 0.52])  # Zoom pour voir les diffÃ©rences\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2fd1f",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation avec Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Cross-Validation LightGBM avec Time Series Split (8 splits)...\\n\")\n",
    "\n",
    "n_splits = 8\n",
    "train_dates_cv = train_data['TS'].unique()\n",
    "cv_scores = []\n",
    "cv_models = []\n",
    "\n",
    "splits = KFold(n_splits=n_splits, random_state=42, shuffle=True).split(train_dates_cv)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(splits):\n",
    "    train_dates_fold = train_dates_cv[train_idx]\n",
    "    val_dates_fold = train_dates_cv[val_idx]\n",
    "    \n",
    "    fold_train_mask = train_data['TS'].isin(train_dates_fold)\n",
    "    fold_val_mask = train_data['TS'].isin(val_dates_fold)\n",
    "    \n",
    "    X_fold_train = X[fold_train_mask]\n",
    "    y_fold_train = y[fold_train_mask]\n",
    "    X_fold_val = X[fold_val_mask]\n",
    "    y_fold_val = y[fold_val_mask]\n",
    "    \n",
    "    # EntraÃ®nement\n",
    "    lgbm_data = lgbm.Dataset(X_fold_train, label=y_fold_train)\n",
    "    model = lgbm.train(lgbm_params, lgbm_data, num_boost_round=300, valid_names=['train'])\n",
    "    \n",
    "    # Ã‰valuation\n",
    "    y_pred = (model.predict(X_fold_val) > 0.5).astype(int)\n",
    "    score = accuracy_score(y_fold_val, y_pred)\n",
    "    cv_scores.append(score)\n",
    "    cv_models.append(model)\n",
    "    \n",
    "    print(f\"Fold {i+1:2d}/{n_splits} - Accuracy: {score:.4f}\")\n",
    "\n",
    "mean_score = np.mean(cv_scores)\n",
    "std_score = np.std(cv_scores)\n",
    "print(f\"\\nðŸ“Š RÃ©sultat CV LightGBM:\")\n",
    "print(f\"  Mean Accuracy: {mean_score:.4f}\")\n",
    "print(f\"  Std Dev: {std_score:.4f}\")\n",
    "print(f\"  Range: [{mean_score - std_score:.4f}, {mean_score + std_score:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des scores CV\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, n_splits+1), cv_scores, marker='o', linewidth=2, markersize=8)\n",
    "plt.axhline(y=mean_score, color='r', linestyle='--', label=f'Mean: {mean_score:.4f}')\n",
    "plt.fill_between(range(1, n_splits+1), mean_score - std_score, mean_score + std_score, alpha=0.2)\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Evolution de l\\'Accuracy par fold (CV LightGBM)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400dbdb",
   "metadata": {},
   "source": [
    "## 7. Analyse de l'Importance des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a09048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des features - Moyenne sur tous les modÃ¨les CV\n",
    "print(\"ðŸ“Š Feature Importance (moyenne des 8 folds):\\n\")\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': np.mean([model.feature_importance(importance_type='gain') for model in cv_models], axis=0)\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "print(feature_importance_df.head(20).to_string(index=False))\n",
    "\n",
    "# Top 20 features\n",
    "top_20_importance = feature_importance_df.head(20)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(top_20_importance)), top_20_importance['Importance'].values)\n",
    "plt.yticks(range(len(top_20_importance)), top_20_importance['Feature'].values)\n",
    "plt.xlabel('Importance (Gain)')\n",
    "plt.title('Top 20 Features par Importance (LightGBM)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarder top 30 features pour Ã©ventuellement les utiliser\n",
    "top_30_features = feature_importance_df.head(30)['Feature'].tolist()\n",
    "print(f\"\\nâœ“ Top 30 features identifiÃ©es: {top_30_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddffacb",
   "metadata": {},
   "source": [
    "## 8. EntraÃ®nement du ModÃ¨le Final et PrÃ©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1bf983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EntraÃ®ner le modÃ¨le final sur TOUTES les donnÃ©es d'entraÃ®nement\n",
    "print(\"ðŸš€ EntraÃ®nement du modÃ¨le final sur toutes les donnÃ©es...\\n\")\n",
    "\n",
    "lgbm_final_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"num_threads\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"verbosity\": -1,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 5,\n",
    "    \"num_leaves\": 31,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "}\n",
    "\n",
    "train_data_final = lgbm.Dataset(X, label=y)\n",
    "model_final = lgbm.train(lgbm_final_params, train_data_final, num_boost_round=300, valid_names=['train'])\n",
    "\n",
    "print(\"âœ“ ModÃ¨le final entraÃ®nÃ©\")\n",
    "\n",
    "# GÃ©nÃ©rer les prÃ©dictions sur le test set\n",
    "print(f\"\\nðŸ“Š GÃ©nÃ©ration des prÃ©dictions sur {X_test.shape[0]} samples...\\n\")\n",
    "\n",
    "# PrÃ©dictions brutes\n",
    "X_test_features = X_test[all_features].fillna(0)\n",
    "predictions_raw = model_final.predict(X_test_features)\n",
    "\n",
    "# Conversion en classes\n",
    "predictions_binary = (predictions_raw > 0.5).astype(int)\n",
    "\n",
    "print(f\"âœ“ PrÃ©dictions gÃ©nÃ©rÃ©es\")\n",
    "print(f\"  Distribution: {np.bincount(predictions_binary)}\")\n",
    "print(f\"  Proportion positif: {predictions_binary.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a463480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble: Moyenne des prÃ©dictions des modÃ¨les CV (stacking simple)\n",
    "print(\"\\nðŸ“ˆ GÃ©nÃ©ration d'un ensemble (ensemble moyenne des CV folds)...\\n\")\n",
    "\n",
    "ensemble_predictions = np.zeros(len(X_test_features))\n",
    "for i, model in enumerate(cv_models):\n",
    "    pred = model.predict(X_test_features)\n",
    "    ensemble_predictions += pred\n",
    "    print(f\"  Fold {i+1}: {(pred > 0.5).mean():.2%} positif\")\n",
    "\n",
    "ensemble_predictions /= len(cv_models)\n",
    "ensemble_binary = (ensemble_predictions > 0.5).astype(int)\n",
    "\n",
    "print(f\"\\nâœ“ Ensemble gÃ©nÃ©rÃ©\")\n",
    "print(f\"  Distribution: {np.bincount(ensemble_binary)}\")\n",
    "print(f\"  Proportion positif: {ensemble_binary.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c04de",
   "metadata": {},
   "source": [
    "## 9. GÃ©nÃ©ration des Fichiers de Soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bdf331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Soumission avec le modÃ¨le final\n",
    "submission_final = sample_submission.copy()\n",
    "submission_final['target'] = predictions_binary\n",
    "submission_final.to_csv('submission_lgbm_final.csv')\n",
    "print(\"âœ“ submission_lgbm_final.csv sauvegardÃ©e\")\n",
    "\n",
    "# Option 2: Soumission avec l'ensemble (meilleure pratique)\n",
    "submission_ensemble = sample_submission.copy()\n",
    "submission_ensemble['target'] = ensemble_binary\n",
    "submission_ensemble.to_csv('submission_ensemble.csv')\n",
    "print(\"âœ“ submission_ensemble.csv sauvegardÃ©e\")\n",
    "\n",
    "# Option 3: Soumission avec Ridge (baseline)\n",
    "ridge_test_pred = (ridge.predict(X_test[all_features].fillna(0)) > 0.5).astype(int)\n",
    "submission_ridge = sample_submission.copy()\n",
    "submission_ridge['target'] = ridge_test_pred\n",
    "submission_ridge.to_csv('submission_ridge_baseline.csv')\n",
    "print(\"âœ“ submission_ridge_baseline.csv sauvegardÃ©e\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ VÃ©rification des fichiers gÃ©nÃ©rÃ©s:\")\n",
    "print(f\"  submission_lgbm_final.csv: {submission_final.shape}\")\n",
    "print(f\"  submission_ensemble.csv: {submission_ensemble.shape}\")\n",
    "print(f\"  submission_ridge_baseline.csv: {submission_ridge.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa145b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un aperÃ§u des prÃ©dictions\n",
    "print(\"\\nðŸ“Š AperÃ§u des prÃ©dictions:\\n\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Ridge': submission_ridge['target'].values,\n",
    "    'LightGBM_Final': submission_final['target'].values,\n",
    "    'Ensemble': submission_ensemble['target'].values\n",
    "})\n",
    "\n",
    "print(\"Premiers 10 exemples:\")\n",
    "print(comparison.head(10).to_string())\n",
    "\n",
    "print(\"\\nAccord entre modÃ¨les:\")\n",
    "print(f\"  Ridge vs LightGBM: {(comparison['Ridge'] == comparison['LightGBM_Final']).mean():.2%}\")\n",
    "print(f\"  Ridge vs Ensemble: {(comparison['Ridge'] == comparison['Ensemble']).mean():.2%}\")\n",
    "print(f\"  LightGBM vs Ensemble: {(comparison['LightGBM_Final'] == comparison['Ensemble']).mean():.2%}\")\n",
    "\n",
    "# Distribution des prÃ©dictions\n",
    "print(f\"\\nDistribution des prÃ©dictions:\")\n",
    "print(f\"  Ridge - Positif: {submission_ridge['target'].sum():5d} ({submission_ridge['target'].mean():.2%})\")\n",
    "print(f\"  LightGBM - Positif: {submission_final['target'].sum():5d} ({submission_final['target'].mean():.2%})\")\n",
    "print(f\"  Ensemble - Positif: {submission_ensemble['target'].sum():5d} ({submission_ensemble['target'].mean():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67366915",
   "metadata": {},
   "source": [
    "## 10. RÃ©sumÃ© ExÃ©cutif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RÃ‰SUMÃ‰ EXÃ‰CUTIF - PRÃ‰DICTION ALLOCATIONS D'ACTIFS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nðŸ“Š DONNÃ‰ES:\")\n",
    "print(f\"  - Ensemble d'entraÃ®nement: {X.shape[0]:,} samples Ã— {X.shape[1]} features\")\n",
    "print(f\"  - Ensemble de test: {X_test_features.shape[0]:,} samples\")\n",
    "print(f\"  - Ã‰quilibre des classes: {y.mean():.1%} positif / {(1-y.mean()):.1%} nÃ©gatif\")\n",
    "\n",
    "print(f\"\\nðŸ”§ FEATURES ENGINEERING:\")\n",
    "print(f\"  - Base features: 41 (RET, SIGNED_VOLUME, MEDIAN_DAILY_TURNOVER)\")\n",
    "print(f\"  - Features dÃ©rivÃ©es: {len(all_features) - 41}\")\n",
    "print(f\"  - Total features: {len(all_features)}\")\n",
    "\n",
    "print(f\"\\nðŸ¤– MODÃˆLES ENTRAÃŽNÃ‰S:\")\n",
    "print(f\"  - Ridge Regression: Val Accuracy = {ridge_val_acc:.4f}\")\n",
    "print(f\"  - Logistic Regression: Val Accuracy = {logistic_val_acc:.4f}\")\n",
    "print(f\"  - Random Forest: Val Accuracy = {rf_val_acc:.4f}\")\n",
    "print(f\"  - LightGBM: Val Accuracy = {lgbm_val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nâœ“ CROSS-VALIDATION LIGHTGBM (8 folds):\")\n",
    "print(f\"  - Mean Accuracy: {mean_score:.4f}\")\n",
    "print(f\"  - Std Dev: {std_score:.4f}\")\n",
    "print(f\"  - Confidence Interval: [{mean_score - std_score:.4f}, {mean_score + std_score:.4f}]\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ TOP 5 FEATURES (par importance):\")\n",
    "for i, (feat, imp) in enumerate(feature_importance_df.head(5).values, 1):\n",
    "    print(f\"  {i}. {feat}: {imp:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ PRÃ‰DICTIONS GÃ‰NÃ‰RÃ‰ES:\")\n",
    "print(f\"  - ModÃ¨le Final (LightGBM sur all data)\")\n",
    "print(f\"    â†’ Positif: {submission_final['target'].sum():,} ({submission_final['target'].mean():.2%})\")\n",
    "print(f\"  - Ensemble (moyenne 8 CV folds)\")\n",
    "print(f\"    â†’ Positif: {submission_ensemble['target'].sum():,} ({submission_ensemble['target'].mean():.2%})\")\n",
    "print(f\"  - Ridge Baseline\")\n",
    "print(f\"    â†’ Positif: {submission_ridge['target'].sum():,} ({submission_ridge['target'].mean():.2%})\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ FICHIERS GÃ‰NÃ‰RÃ‰S:\")\n",
    "print(f\"  âœ“ submission_lgbm_final.csv\")\n",
    "print(f\"  âœ“ submission_ensemble.csv\")\n",
    "print(f\"  âœ“ submission_ridge_baseline.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMANDATION: Soumettre 'submission_ensemble.csv' (moyenne CV)\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
