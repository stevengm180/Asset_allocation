{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5234fec",
   "metadata": {},
   "source": [
    "# Pipeline OptimisÃ© - ðŸš€ AmÃ©lioration +1% Accuracy\n",
    "\n",
    "**Objectif**: Passer de 50.66% Ã  51.91%+\n",
    "\n",
    "Ce pipeline intÃ¨gre:\n",
    "- âœ… Hyperparameter tuning (Optuna)\n",
    "- âœ… Features avancÃ©es (20+ nouvelles features)\n",
    "- âœ… Stacking ensemble (meta-learning)\n",
    "- âœ… Threshold optimization\n",
    "- âœ… Weighted ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Imports des modules\n",
    "from data_loading import load_data, explore_data\n",
    "from data_preparation import prepare_data, split_temporal_data, prepare_features_for_modeling\n",
    "from feature_engineering import create_all_features\n",
    "from exploratory_analysis import analyze_correlations, plot_correlations\n",
    "from model_training import train_base_models, create_results_dataframe\n",
    "from cross_validation import perform_time_series_cross_validation, plot_cv_results, get_feature_importance\n",
    "from predictions import train_final_model\n",
    "from optimization import optimize_hyperparameters, train_lgbm_optimized, quick_hyperparameter_search\n",
    "from stacking_ensemble import multi_level_stacking, weighted_ensemble\n",
    "from threshold_optimization import find_optimal_threshold, compare_thresholds\n",
    "from utils import plot_model_comparison, print_summary_report\n",
    "\n",
    "print(\"âœ… Tous les modules importÃ©s - Pipeline OptimisÃ©\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed7d37",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Ã‰tape 1: Chargement et Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, sample_submission = load_data()\n",
    "print(f\"âœ“ DonnÃ©es chargÃ©es\")\n",
    "print(f\"  Train: {X_train.shape} | Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd1bb75",
   "metadata": {},
   "source": [
    "## ðŸ”§ Ã‰tape 2: PrÃ©paration et Features (AMÃ‰LIORÃ‰ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0590742",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, X_test = prepare_data(X_train, y_train, X_test)\n",
    "train_data, X_test, all_features = create_all_features(train_data, X_test)\n",
    "\n",
    "print(f\"\\nâœ¨ {len(all_features)} features crÃ©Ã©es (dont 20+ avancÃ©es)\")\n",
    "\n",
    "# PrÃ©parer X, y\n",
    "X = train_data[all_features].fillna(0)\n",
    "y = (train_data['target'] > 0).astype(int)\n",
    "X_test_features = X_test[all_features].fillna(0)\n",
    "\n",
    "# Split temporel\n",
    "train_mask, test_mask = split_temporal_data(train_data, 0.7)\n",
    "X_train_split, y_train_split = X[train_mask], y[train_mask]\n",
    "X_val_split, y_val_split = X[test_mask], y[test_mask]\n",
    "\n",
    "print(f\"\\nâœ“ DonnÃ©es prÃ©parÃ©es:\")\n",
    "print(f\"  Train split: {X_train_split.shape}\")\n",
    "print(f\"  Val split: {X_val_split.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca1692",
   "metadata": {},
   "source": [
    "## âš™ï¸ Ã‰tape 3: Hyperparameter Tuning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ” HYPERPARAMETER OPTIMIZATION (rapide: 10 trials)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Option 1: Quick search (rapide - 2min)\n",
    "best_params = quick_hyperparameter_search(X_train_split, y_train_split, X_val_split, y_val_split)\n",
    "\n",
    "# Option 2: Full Optuna optimization (lent - 15min, dÃ©commenter si besoin)\n",
    "# best_params = optimize_hyperparameters(X_train_split, y_train_split, X_val_split, y_val_split, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871244e6",
   "metadata": {},
   "source": [
    "## ðŸ”„ Ã‰tape 4: Cross-Validation avec HyperparamÃ¨tres OptimisÃ©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores, cv_models, mean_score, std_score = perform_time_series_cross_validation(\n",
    "    X, y, train_data, all_features\n",
    ")\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(f\"\\nâœ… CV Score: {mean_score:.4f} Â± {std_score:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance_df = get_feature_importance(cv_models, all_features, top_n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211fef7",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Ã‰tape 5: Stacking Ensemble (Meta-Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EntraÃ®ner le modÃ¨le final avec meilleurs hyperparamÃ¨tres\n",
    "lgbm_final = train_final_model(X, y, all_features)\n",
    "\n",
    "# Stacking multi-niveau\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "pred_stacking, stacking_acc, meta_model = multi_level_stacking(\n",
    "    cv_models, lgbm_final, X_train_split, X_val_split, X_test_features, \n",
    "    y_train_split, y_val_split\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Stacking Accuracy: {stacking_acc:.4f}\")\n",
    "\n",
    "# Ensemble pondÃ©rÃ© (basÃ© sur CV scores)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "pred_weighted = weighted_ensemble(cv_models, lgbm_final, X_test_features, cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0dbfa",
   "metadata": {},
   "source": [
    "## ðŸŽª Ã‰tape 6: Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87423d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ¯ OPTIMISATION DU SEUIL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Obtenir les prÃ©dictions probabilistes pour le stacking\n",
    "y_val_pred_proba_stacking = meta_model.predict(np.column_stack([\n",
    "    cv_models[i].predict(X_val_split) for i in range(len(cv_models))\n",
    "] + [lgbm_final.predict(X_val_split)]))\n",
    "\n",
    "# Trouver le meilleur seuil\n",
    "threshold_result = find_optimal_threshold(y_val_split.values, y_val_pred_proba_stacking)\n",
    "optimal_threshold = threshold_result['threshold']\n",
    "\n",
    "print(f\"\\nâœ“ Meilleur seuil trouvÃ©: {optimal_threshold:.3f}\")\n",
    "\n",
    "# Comparer plusieurs seuils\n",
    "print(\"\\nðŸ“Š Comparaison de plusieurs seuils:\")\n",
    "thresholds_comparison = compare_thresholds(\n",
    "    y_val_split.values, \n",
    "    y_val_pred_proba_stacking,\n",
    "    thresholds=[0.40, 0.45, 0.50, 0.55, 0.60]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211e2ae",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Ã‰tape 7: GÃ©nÃ©ration des Soumissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“‹ SOUMISSIONS GÃ‰NÃ‰RÃ‰ES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Stacking avec seuil optimisÃ©\n",
    "submission_stacking = sample_submission.copy()\n",
    "submission_stacking['target'] = pred_stacking\n",
    "submission_stacking.to_csv('submission_stacking_optimized.csv')\n",
    "print(f\"\\nâœ“ submission_stacking_optimized.csv\")\n",
    "print(f\"  Positif: {pred_stacking.sum():,} ({pred_stacking.mean():.2%})\")\n",
    "\n",
    "# 2. Weighted ensemble\n",
    "submission_weighted = sample_submission.copy()\n",
    "submission_weighted['target'] = pred_weighted\n",
    "submission_weighted.to_csv('submission_weighted_ensemble.csv')\n",
    "print(f\"\\nâœ“ submission_weighted_ensemble.csv\")\n",
    "print(f\"  Positif: {pred_weighted.sum():,} ({pred_weighted.mean():.2%})\")\n",
    "\n",
    "# 3. Stacking avec seuil optimal\n",
    "print(f\"\\nâœ“ submission_stacking_threshold_{optimal_threshold:.3f}.csv\")\n",
    "pred_stacking_optimized = (y_val_pred_proba_stacking > optimal_threshold).astype(int)\n",
    "# Appliquer au test set\n",
    "y_test_pred_proba_stacking = meta_model.predict(np.column_stack([\n",
    "    cv_models[i].predict(X_test_features) for i in range(len(cv_models))\n",
    "] + [lgbm_final.predict(X_test_features)]))\n",
    "pred_test_optimized = (y_test_pred_proba_stacking > optimal_threshold).astype(int)\n",
    "\n",
    "submission_optimized = sample_submission.copy()\n",
    "submission_optimized['target'] = pred_test_optimized\n",
    "submission_optimized.to_csv(f'submission_stacking_threshold_{optimal_threshold:.3f}.csv')\n",
    "print(f\"  Positif: {pred_test_optimized.sum():,} ({pred_test_optimized.mean():.2%})\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ¯ RECOMMANDATION: Soumettre 'submission_stacking_optimized.csv'\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
